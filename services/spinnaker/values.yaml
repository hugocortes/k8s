halyard:
  spinnakerVersion: 1.25.0
  image:
    tag: 1.42.1

  # see config.example.yaml
  # additionalSecrets: {}

  additionalScripts:
    enabled: true
    configMapName: spinnaker-halyard-config
    configMapKey: config.sh
    create: true
    data:
      # see config.example.yaml
      # enable_canary.sh: |-

      enable_helm_artifact.sh: |-
        echo "enabling helm artifact"
        $HAL_COMMAND config artifact helm enable
        $HAL_COMMAND config artifact helm account add bitnami \
          --repository https://charts.bitnami.com/bitnami
        $HAL_COMMAND config artifact helm account add chartmuseum \
          --repository http://chartmuseum.ops:8080
        $HAL_COMMAND config artifact helm account add concourse \
          --repository https://concourse-charts.storage.googleapis.com
        $HAL_COMMAND config artifact helm account add codecentric \
          --repository https://codecentric.github.io/helm-charts
        $HAL_COMMAND config artifact helm account add elastic \
          --repository https://helm.elastic.co
        $HAL_COMMAND config artifact helm account add hashicorp \
          --repository https://helm.releases.hashicorp.com
        $HAL_COMMAND config artifact helm account add influxdata \
          --repository https://helm.influxdata.com
        $HAL_COMMAND config artifact helm account add jaegertracing \
          --repository https://jaegertracing.github.io/helm-charts
        $HAL_COMMAND config artifact helm account add jetstack \
          --repository https://charts.jetstack.io
        $HAL_COMMAND config artifact helm account add kiali \
          --repository https://kiali.org/helm-charts
        $HAL_COMMAND config artifact helm account add nfs-subdir-external-provisioner \
          --repository https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner
        $HAL_COMMAND config artifact helm account add openfaas \
          --repository https://openfaas.github.io/faas-netes
        $HAL_COMMAND config artifact helm account add pomerium \
          --repository https://helm.pomerium.io
        $HAL_COMMAND config artifact helm account add prometheus-community \
          --repository https://prometheus-community.github.io/helm-charts
        $HAL_COMMAND config artifact helm account add stable \
          --repository https://storage.googleapis.com/homelabops-public
      enable_gcs.sh: |-
        echo "enabling gcs artifact"
        $HAL_COMMAND config artifact gcs enable
        $HAL_COMMAND config artifact gcs account add gcs \
          --json-path /opt/gcs/key.json
      enable_no_auth_http.sh: |-
        echo "enabling http artifact"
        $HAL_COMMAND config artifact http enable
      configure_component_sizing.sh: |-
        echo "configuring component sizing"
        # requires replica=1
        $HAL_COMMAND config deploy component-sizing echo edit \
          --container-limits-cpu 250m \
          --container-requests-cpu 150m \
          --container-limits-memory 1Gi \
          --container-requests-memory 1Gi
        $HAL_COMMAND config deploy component-sizing igor edit \
          --container-limits-cpu 250m \
          --container-requests-cpu 150m \
          --container-limits-memory 750Mi \
          --container-requests-memory 750Mi

        # requires more resources
        $HAL_COMMAND config deploy component-sizing clouddriver edit \
          --container-limits-cpu 2.5 \
          --container-requests-cpu 2 \
          --container-limits-memory 2Gi \
          --container-requests-memory 2Gi \
          --replicas 1
        $HAL_COMMAND config deploy component-sizing orca edit \
          --container-limits-cpu 1 \
          --container-requests-cpu 750m \
          --container-limits-memory 1.5Gi \
          --container-requests-memory 1.5Gi \
          --replicas 1

        $HAL_COMMAND config deploy component-sizing deck edit \
          --container-limits-cpu 250m \
          --container-requests-cpu 150m \
          --container-limits-memory 250Mi \
          --container-requests-memory 250Mi
        $HAL_COMMAND config deploy component-sizing front50 edit \
          --container-limits-cpu 250m \
          --container-requests-cpu 150m \
          --container-limits-memory 750Mi \
          --container-requests-memory 750Mi
        $HAL_COMMAND config deploy component-sizing gate edit \
          --container-limits-cpu 250m \
          --container-requests-cpu 150m \
          --container-limits-memory 750Mi \
          --container-requests-memory 750Mi
        $HAL_COMMAND config deploy component-sizing kayenta edit \
          --container-limits-cpu 250m \
          --container-requests-cpu 150m \
          --container-limits-memory 1.25Gi \
          --container-requests-memory 1.25Gi
        $HAL_COMMAND config deploy component-sizing rosco edit \
          --container-limits-cpu 250m \
          --container-requests-cpu 150m \
          --container-limits-memory 500Mi \
          --container-requests-memory 500Mi
  additionalProfileConfigMaps:
    data:
      clouddriver-local.yml:
        env:
          JAVA_OPTS: "-XX:MaxRAMPercentage=90.0"
        # see config.example.yaml
        # services: {}
      deck-local.yml:
        env:
          JAVA_OPTS: "-XX:MaxRAMPercentage=90.0"
      echo-local.yml:
        env:
          JAVA_OPTS: "-XX:MaxRAMPercentage=90.0"
        # see config.example.yaml
        # mail: {}
        # spring: {}
      front50-local.yml:
        env:
          JAVA_OPTS: "-XX:MaxRAMPercentage=90.0"
      gate-local.yml:
        env:
          JAVA_OPTS: "-XX:MaxRAMPercentage=90.0"
        okHttpClient:
          connectTimeoutMs: 90000
          readTimeoutMs: 90000
        # see config.example.yaml
        # security: {}
        server:
          tomcat:
            protocolHeader: X-Forwarded-Proto
            remoteIpHeader: X-Forwarded-For
            internalProxies: .*
      # fast forwarding
      # curl -X POST $IGOR/admin/pollers/fastforward/dockerTagMonitor?partition=
      igor-local.yml:
        env:
          JAVA_OPTS: "-XX:MaxRAMPercentage=90.0"
        spinnaker:
          pollInterval: 180
          pollingSafeguard:
            itemUpperThreshold: 50000
        okHttpClient:
          connectTimeoutMs: 90000
          readTimeoutMs: 90000
        # see config.example.yaml
        # services: {}
      kayenta-loca.yml:
        env:
          JAVA_OPTS: "-XX:MaxRAMPercentage=90.0"
        okHttpClient:
          connectTimeoutMs: 90000
          readTimeoutMs: 90000
      orca-local.yml:
        env:
          JAVA_OPTS: "-XX:MaxRAMPercentage=90.0"
        pollers:
          oldPipelineCleanup:
            enabled: true
            intervalMs: 3600000
            thresholdDays: 14
            minimumPipelineExecutions: 5
        tasks:
          daysOfExecutionHistory: 14
        okHttpClient:
          connectTimeoutMs: 90000
          readTimeoutMs: 90000
        # see config.example.yaml
        # services: {}
      rosco-local.yml:
        env:
          JAVA_OPTS: "-XX:MaxRAMPercentage=90.0"
        okHttpClient:
          connectTimeoutMs: 90000
          readTimeoutMs: 90000
        # see config.example.yaml
        # services: {}
      settings-local.js: |
        window.spinnakerSettings.notifications.email = {
          enabled: true
        }
      spinnaker-local.yml:
        redis:
          timeout: 45000
        logging:
          level:
            com:
              netflix:
                spinnaker: ERROR
              retrofit: ERROR
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 1
      memory: 1.25Gi
  env:
    - name: JAVA_OPTS
      value: -XX:MaxRAMPercentage=90.0

# see config.example.yaml
# dockerRegistryAccountSecret: "" 
dockerRegistries:

- name: dockerhub
  address: index.docker.io
  username: hugocortes
  repositories:
  - library/elasticsearch
  - library/logstash
  - library/kibana
  - bitnami/metallb-controller
  - bitnami/metallb-speaker
  - bitnami/mongodb
  - bitnami/postgresql
  - chartmuseum/chartmuseum
  - concoursee/concourse
  - governmentpaas/curl-ssl
  - grafana/grafana
  - graylog/graylog
  - hashicorp/vault-k8s
  - hugocortes/backup
  - hugocortes/keycloak-extensions
  - hugocortes/me
  - hugocortes/ynab-metrics
  - idobry/chartmuseumui
  - jaegertracing/jaeger-agent
  - jaegertracing/jaeger-cassandra-schema
  - jaegertracing/jaeger-collector
  - jaegertracing/jaeger-es-index-cleaner
  - jaegertracing/jaeger-es-rollover
  - jaegertracing/jaeger-ingester
  - jaegertracing/jaeger-query
  - jaegertracing/spark-dependencies
  - jboss/keycloak
  - kennethreitz/httpbin
  - keycloak/keycloak-gatekeeper
  - library/influxdb
  - library/mysql
  - library/nginx
  - library/vault
  - linuxserver/bookstack
  - linuxserver/jackett
  - linuxserver/ombi
  - linuxserver/radarr
  - linuxserver/sabnzbd
  - linuxserver/sonarr
  - linuxserver/transmission
  - plexinc/pms-docker
  - miniflux/miniflux
  - pomerium/pomerium
  - prom/prometheus
  - rmountjoy/dashmachine
  - tautulli/tautulli
  - technosoft2000/calibre-web
  - usefathom/fathom
- name: gcr
  address: k8s.gcr.io
  repositories:
  - google-containers/metrics-server-amd64
  - google-containers/metrics-server-arm
  - kube-state-metrics/kube-state-metrics
  - sig-storage/nfs-subdir-external-provisioner
- name: quay
  address: quay.io
  repositories:
  - kiali/kiali
  - prometheus/node-exporter
  - prometheus/prometheus
spinnakerFeatureFlags:
  - pipeline-templates
  - managed-pipeline-templates-v2-ui
minio:
  enabled: false
# see config.example.yaml
gcs:
  enabled: true
# see config.example.yaml
redis:
  enabled: false
# see config.example.yaml
kubeConfig:
  enabled: true
  omittedNameSpaces:
  - kube-public
