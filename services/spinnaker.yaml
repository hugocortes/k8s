---

halyard:
  spinnakerVersion: 1.20.0
  image:
    tag: 1.34.0
  additionalSecrets:
    name: ""
  additionalScripts:
    enabled: true
    configMapName: spinnaker-halyard-config
    configMapKey: config.sh
    create: true
    data:
      enable_helm_artifact.sh: |-
        echo "enabling helm artifact"
        $HAL_COMMAND config artifact helm enable
        $HAL_COMMAND config artifact helm account add bitnami \
          --repository https://charts.bitnami.com/bitnami
        $HAL_COMMAND config artifact helm account add chartmuseum \
          --repository http://chartmuseum.storage:8080
        $HAL_COMMAND config artifact helm account add concourse \
          --repository https://concourse-charts.storage.googleapis.com
        $HAL_COMMAND config artifact helm account add codecentric \
          --repository https://codecentric.github.io/helm-charts
        $HAL_COMMAND config artifact helm account add elastic \
          --repository https://helm.elastic.co
        $HAL_COMMAND config artifact helm account add hashicorp \
          --repository https://helm.releases.hashicorp.com
        $HAL_COMMAND config artifact helm account add influxdata \
          --repository https://helm.influxdata.com
        $HAL_COMMAND config artifact helm account add istio-1.4 \
          --repository https://storage.googleapis.com/istio-release/releases/1.4.4/charts
        $HAL_COMMAND config artifact helm account add istio-1.5 \
          --repository https://storage.googleapis.com/istio-release/releases/1.5.6/charts
        $HAL_COMMAND config artifact helm account add jetstack \
          --repository https://charts.jetstack.io
        $HAL_COMMAND config artifact helm account add openfaas \
          --repository https://openfaas.github.io/faas-netes
        $HAL_COMMAND config artifact helm account add pomerium \
          --repository https://helm.pomerium.io
        $HAL_COMMAND config artifact helm account add stable \
          --repository https://storage.googleapis.com/homelabprojects-public
      enable_gcs.sh: |-
        echo "enabling gcs artifact"
        $HAL_COMMAND config artifact gcs enable
        $HAL_COMMAND config artifact gcs account add gcs \
          --json-path /opt/gcs/key.json
      enable_no_auth_http.sh: |-
        echo "enabling http artifact"
        $HAL_COMMAND config artifact http enable
      enable_metrics.sh: |-
        echo "enabling prometheus"
        $HAL_COMMAND config metric-stores prometheus enable
      configure_kubernetes.sh: |-
        echo "configuring kubernetes accounts"
        $HAL_COMMAND config provider kubernetes account edit prometheus \
          --live-manifest-calls true
        $HAL_COMMAND config provider kubernetes account edit hestia \
          --live-manifest-calls true
        $HAL_COMMAND config provider kubernetes account edit athens \
          --live-manifest-calls true
      configure_component_sizing.sh: |-
        echo "configuring component sizing"
        # requires replica=1
        $HAL_COMMAND config deploy component-sizing echo edit \
          --container-limits-cpu 250m \
          --container-requests-cpu 100m \
          --container-limits-memory 1Gi \
          --container-requests-memory 1Gi
        $HAL_COMMAND config deploy component-sizing igor edit \
          --container-limits-cpu 250m \
          --container-requests-cpu 100m \
          --container-limits-memory 700Mi \
          --container-requests-memory 700Mi

        # requires more resources
        $HAL_COMMAND config deploy component-sizing clouddriver edit \
          --container-limits-cpu 1.5 \
          --container-requests-cpu 750m \
          --container-limits-memory 1.75Gi \
          --container-requests-memory 1.75Gi \
          --replicas 1
        $HAL_COMMAND config deploy component-sizing orca edit \
          --container-limits-cpu 500m \
          --container-requests-cpu 500m \
          --container-limits-memory 1Gi \
          --container-requests-memory 1Gi \
          --replicas 1

        $HAL_COMMAND config deploy component-sizing deck edit \
          --container-limits-cpu 250m \
          --container-requests-cpu 100m \
          --container-limits-memory 100Mi \
          --container-requests-memory 100Mi
        $HAL_COMMAND config deploy component-sizing front50 edit \
          --container-limits-cpu 250m \
          --container-requests-cpu 150m \
          --container-limits-memory 1Gi \
          --container-requests-memory 1Gi
        $HAL_COMMAND config deploy component-sizing gate edit \
          --container-limits-cpu 250m \
          --container-requests-cpu 150m \
          --container-limits-memory 1Gi \
          --container-requests-memory 1Gi
        $HAL_COMMAND config deploy component-sizing rosco edit \
          --container-limits-cpu 250m \
          --container-requests-cpu 100m \
          --container-limits-memory 500Mi \
          --container-requests-memory 500Mi
  additionalProfileConfigMaps:
    data:
      clouddriver-local.yml:
        env:
          JAVA_OPTS: "-XX:MaxRAMPercentage=90.0"
        services:
          redis:
            baseUrl: ""
      deck-local.yml:
        env:
          JAVA_OPTS: "-XX:MaxRAMPercentage=90.0"
      echo-local.yml:
        env:
          JAVA_OPTS: "-XX:MaxRAMPercentage=90.0"
        mail:
          enabled: true
          from: ""
        spring:
          mail:
            host: ""
            username: ""
            password: ""
            port: 587
            properties:
              mail:
                smtp:
                  auth: true
                  starttls:
                    enable: true
                transport:
                  protocol: true
      front50-local.yml:
        env:
          JAVA_OPTS: "-XX:MaxRAMPercentage=90.0"
        sql:
          enabled: true
          connectionPools:
            default:
              # https://github.com/spinnaker/kork/blob/master/kork-sql/src/main/kotlin/com/netflix/spinnaker/kork/sql/config/ConnectionPoolProperties.kt
              default: true
              jdbcUrl: ""
              user: ""
              password: ""
              connectionTimeout: 15000
              maxLifetime: 90000
              maxPoolSize: 100
          migration:
            jdbcUrl: ""
            user: ""
            password: ""
            connectionTimeout: 15000
            maxLifetime: 90000
            maxPoolSize: 100
        spinnaker:
          gcs:
            enabled: false
      gate-local.yml:
        env:
          JAVA_OPTS: "-XX:MaxRAMPercentage=90.0"
        security:
          oauth2:
            client:
              # clientId: 
              # clientSecret:
              # userAuthorizationUri:
              # accessTokenUri:
              scope: openid email profile
            resource: {}
              # userInfoUri:
            userInfoMapping:
              email: email
              firstName: given_name
              lastName: family_name
              username: preferred_username
        tomcat:
          protocolHeader: X-Forwarded-Proto
          remoteIpHeader: X-Forwarded-For
          internalProxies: .*
      igor-local.yml:
        env:
          JAVA_OPTS: "-XX:MaxRAMPercentage=90.0"
        spinnaker:
          pollInterval: 60
          pollingSafeguard:
            itemUpperThreshold: 40000
      orca-local.yml:
        env:
          JAVA_OPTS: "-XX:MaxRAMPercentage=90.0"
        services:
          redis:
            baseUrl: ""
        pollers:
          oldPipelineCleanup:
            enabled: true
            intervalMs: 3600000
            thresholdDays: 14
            minimumPipelineExecutions: 5
        tasks:
          daysOfExecutionHistory: 14
        okHttpClient:
          connectTimeoutMs: 120000
          readTimeoutMs: 120000
      rosco-local.yml:
        env:
          JAVA_OPTS: "-XX:MaxRAMPercentage=90.0"
        okHttpClient:
          connectTimeoutMs: 120000
          readTimeoutMs: 120000
      settings-local.js: |
        window.spinnakerSettings.notifications.email = {
          enabled: true
        }
      spinnaker-local.yml:
        logging:
          level:
            com:
              netflix:
                spinnaker: WARN
              retrofit: WARN
  resources:
    requests:
      cpu: 750m
      memory: 1.5Gi
    limits:
      cpu: 750m
      memory: 1.5Gi
dockerRegistries:
- name: dockerhub
  address: index.docker.io
  repositories:
  - bitnami/mongodb
  - bitnami/postgresql
  - bitnami/redis
  - chartmuseum/chartmuseum
  - governmentpaas/curl-ssl
  - grafana/grafana
  - graylog/graylog
  - hashicorp/vault-k8s
  - hugocortes/me
  - idobry/chartmuseumui
  - jboss/keycloak
  - kennethreitz/httpbin
  - keycloak/keycloak-gatekeeper
  - library/elasticsearch
  - library/influxdb
  - library/mysql
  - library/nginx
  - library/vault
  - linuxserver/bookstack
  - linuxserver/grocy
  - linuxserver/jackett
  - linuxserver/ombi
  - linuxserver/radarr
  - linuxserver/sabnzbd
  - linuxserver/sonarr
  - linuxserver/transmission
  - metallb/controller
  - metallb/speaker
  - plexinc/pms-docker
  - miniflux/miniflux
  - pomerium/pomerium
  - prom/prometheus
  - rmountjoy/dashmachine
  - tautulli/tautulli
  - technosoft2000/calibre-web
  - usefathom/fathom
- name: gcr
  address: gcr.io
  repositories:
  - google-containers/metrics-server-amd64
  - google-containers/metrics-server-arm
- name: quay
  address: quay.io
  repositories:
  - external_storage/nfs-client-provisioner
spinnakerFeatureFlags:
  - pipeline-templates
  - managed-pipeline-templates-v2-ui
minio:
  enabled: false
gcs:
  enabled: true
redis:
  enabled: false
  external:
    host: ""
    port: ""
    password: ""
kubeConfig:
  enabled: true
  secretName: ""
  secretKey: config
  contexts:
  - prometheus
  - hestia
  - athens
  deploymentContext: prometheus
  omittedNameSpaces:
  - kube-public
